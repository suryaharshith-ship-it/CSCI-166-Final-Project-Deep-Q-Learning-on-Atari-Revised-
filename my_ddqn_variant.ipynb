{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "my_ddqn_variant.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test 3 --- Final Test for 06.11.2025"
      ],
      "metadata": {
        "id": "XtOuIKifmmyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]\n",
        "!pip install autorom\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqL9333gml9l",
        "outputId": "1714a070-c267-4a75-9232-888338444bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
            "Collecting autorom\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from autorom) (8.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autorom) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2025.11.12)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: autorom\n",
            "Successfully installed autorom-0.6.1\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi2qmVoVmxve",
        "outputId": "9f1c3e4c-116e-455f-fb8f-499e02200ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.12/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.12/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Gym"
      ],
      "metadata": {
        "id": "RQyqgMFzT-qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "import gymnasium as gym"
      ],
      "metadata": {
        "id": "_W_afhrzUAnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the model save drive"
      ],
      "metadata": {
        "id": "E0n7zQrALq7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive 2>/dev/null\n",
        "!rm -rf /content/drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IerFXMHhjPjt",
        "outputId": "139a00d3-6972-4b3d-8e9d-1aaf3326fcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_dir = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "vlWPUjKfLv9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Model"
      ],
      "metadata": {
        "id": "SAEvyoukL1T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import argparse\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import collections\n",
        "import typing as tt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard.writer import SummaryWriter"
      ],
      "metadata": {
        "id": "VCbjkLLSxCUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "    def forward(self, x: torch.ByteTensor):\n",
        "        x = x.float() / 255.0\n",
        "        return self.fc(self.conv(x))"
      ],
      "metadata": {
        "id": "dIJ32Rs6xJsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wrappers\n",
        "\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common import atari_wrappers\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    ImageToPyTorch: Reorders image dimensions from (H, W, C) to (C, H, W)\n",
        "    for compatibility with PyTorch convolutional layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        obs = self.observation_space\n",
        "        assert isinstance(obs, gym.spaces.Box)\n",
        "        assert len(obs.shape) == 3\n",
        "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(),\n",
        "            shape=new_shape, dtype=obs.dtype)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    BufferWrapper: Maintains a rolling window of the last `n_steps` frames\n",
        "    to give the agent a sense of temporal context.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, n_steps):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        obs = env.observation_space\n",
        "        assert isinstance(obs, spaces.Box)\n",
        "        new_obs = gym.spaces.Box(\n",
        "            obs.low.repeat(n_steps, axis=0), obs.high.repeat(n_steps, axis=0),\n",
        "            dtype=obs.dtype)\n",
        "        self.observation_space = new_obs\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "\n",
        "    def reset(self, *, seed: tt.Optional[int] = None, options: tt.Optional[dict[str, tt.Any]] = None):\n",
        "        for _ in range(self.buffer.maxlen):\n",
        "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
        "        obs, extra = self.env.reset()\n",
        "        return self.observation(obs), extra\n",
        "\n",
        "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer)\n",
        "\n",
        "\n",
        "def make_env(env_name: str, n_steps=4, render_mode=None, **kwargs):\n",
        "    print(f\"Creating environment {env_name}\")\n",
        "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
        "    env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=n_steps)\n",
        "    return env"
      ],
      "metadata": {
        "id": "Vk2CtGcOBcQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f42c6d3-35db-40c3-ad99-d35506e177b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Configuration\n",
        "DEFAULT_ENV_NAME = \"ALE/Pong-v5\"\n",
        "MEAN_REWARD_BOUND = 19\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "REPLAY_START_SIZE = 10000\n",
        "\n",
        "SAVE_EPSILON = 0.5  # Only save if at least this much better\n",
        "EPSILON_DECAY_LAST_FRAME = 150000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.01\n",
        "\n",
        "# Tuple of tensors returned from a sampled minibatch in replay buffer\n",
        "State = np.ndarray\n",
        "Action = int\n",
        "BatchTensors = tt.Tuple[\n",
        "    torch.ByteTensor,           # current state\n",
        "    torch.LongTensor,           # actions\n",
        "    torch.Tensor,               # rewards\n",
        "    torch.BoolTensor,           # done || trunc\n",
        "    torch.ByteTensor            # next state\n",
        "]"
      ],
      "metadata": {
        "id": "GvXPdjPCBxOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âš™ï¸ Fast Training Config for Quick Test Run\n",
        "MEAN_REWARD_BOUND = 5\n",
        "REPLAY_START_SIZE = 1000\n",
        "EPSILON_DECAY_LAST_FRAME = 10_000\n",
        "SYNC_TARGET_FRAMES = 500\n",
        "\n",
        "# REPLAY_SIZE = 5000  # optional\n",
        "# BATCH_SIZE = 16     # optional"
      ],
      "metadata": {
        "id": "3FHvHNMrR9Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Define directories\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "\n",
        "# Create both directories if they don't exist\n",
        "os.makedirs(save_dir_drive, exist_ok=True)\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n",
        "\n",
        "# Safe model filename\n",
        "env_name = DEFAULT_ENV_NAME\n",
        "safe_env_name = env_name.replace(\"/\", \"_\")"
      ],
      "metadata": {
        "id": "MkILCuT2OhBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Experience:\n",
        "    state: State\n",
        "    action: Action\n",
        "    reward: float\n",
        "    done_trunc: bool\n",
        "    new_state: State\n",
        "\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience: Experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
        "        indices = np.random.choice(len(self), batch_size, replace=False)\n",
        "        return [self.buffer[idx] for idx in indices]"
      ],
      "metadata": {
        "id": "uW4Bo-mcB6rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self.state: tt.Optional[np.ndarray] = None\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def play_step(self, net: DQN, device: torch.device,\n",
        "                  epsilon: float = 0.0) -> tt.Optional[float]:\n",
        "        done_reward = None\n",
        "\n",
        "        if np.random.random() < epsilon:\n",
        "              action = self.env.action_space.sample()  # use self.env\n",
        "        else:\n",
        "              state_v = torch.as_tensor(self.state).to(device)\n",
        "              state_v.unsqueeze_(0)\n",
        "              q_vals_v = net(state_v)\n",
        "              _, act_v = torch.max(q_vals_v, dim=1)\n",
        "              action = int(act_v.item())\n",
        "\n",
        "\n",
        "        # do step in the environment\n",
        "        new_state, reward, is_done, is_tr, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "\n",
        "        exp = Experience(\n",
        "            state=self.state, action=action, reward=float(reward),\n",
        "            done_trunc=is_done or is_tr, new_state=new_state\n",
        "        )\n",
        "        self.exp_buffer.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done or is_tr:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward"
      ],
      "metadata": {
        "id": "irJb4V32B-R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_tensors(batch: tt.List[Experience], device: torch.device) -> BatchTensors:\n",
        "    states, actions, rewards, dones, new_state = [], [], [], [], []\n",
        "    for e in batch:\n",
        "        states.append(e.state)\n",
        "        actions.append(e.action)\n",
        "        rewards.append(e.reward)\n",
        "        dones.append(e.done_trunc)\n",
        "        new_state.append(e.new_state)\n",
        "    states_t = torch.as_tensor(np.asarray(states))\n",
        "    actions_t = torch.LongTensor(actions)\n",
        "    rewards_t = torch.FloatTensor(rewards)\n",
        "    dones_t = torch.BoolTensor(dones)\n",
        "    new_states_t = torch.as_tensor(np.asarray(new_state))\n",
        "    return states_t.to(device), actions_t.to(device), rewards_t.to(device), \\\n",
        "           dones_t.to(device),  new_states_t.to(device)"
      ],
      "metadata": {
        "id": "vHXmNr_wCBJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n",
        "              device: torch.device) -> torch.Tensor:\n",
        "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
        "    q_sa = net(states_t).gather(1, actions_t.unsqueeze(-1)).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        next_actions = net(new_states_t).argmax(dim=1)\n",
        "        next_q = tgt_net(new_states_t).gather(\n",
        "            1, next_actions.unsqueeze(-1)\n",
        "        ).squeeze(-1)\n",
        "\n",
        "        next_q[dones_t] = 0.0\n",
        "        target = rewards_t + GAMMA * next_q\n",
        "\n",
        "    return nn.MSELoss()(q_sa, target)"
      ],
      "metadata": {
        "id": "-dbh0431CEXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comment = f\"pong_ddqn_variant_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_sync{SYNC_TARGET_FRAMES}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time  # in seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "        #  print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "        #      f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "                f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            # Save to both paths\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"ðŸ’¾ Model saved to:\\n - Google Drive: {model_path_drive}\\n - Local:        {model_path_local}\")\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "        if m_reward > MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            break\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "env.close()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8gj-5woCXEB",
        "outputId": "e8938452-1ecc-405f-8346-fcc11dffe20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Pong-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "230: done 1 games, reward -20.000, eps 0.98, speed 118.37 f/s, time 0.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-20-20251129-2120-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-20-20251129-2120-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "54212: done 184 games, reward -19.490, eps 0.01, speed 108.61 f/s, time 7.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-19-20251129-2128-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-19-20251129-2128-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -20.000 -> -19.490\n",
            "62345: done 199 games, reward -18.980, eps 0.01, speed 129.82 f/s, time 8.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-18-20251129-2129-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-18-20251129-2129-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -19.490 -> -18.980\n",
            "73047: done 219 games, reward -18.460, eps 0.01, speed 111.13 f/s, time 10.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-18-20251129-2130-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-18-20251129-2130-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -18.980 -> -18.460\n",
            "85516: done 239 games, reward -17.940, eps 0.01, speed 114.08 f/s, time 11.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-17-20251129-2132-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-17-20251129-2132-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -18.460 -> -17.940\n",
            "98988: done 261 games, reward -17.430, eps 0.01, speed 130.61 f/s, time 13.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-17-20251129-2134-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-17-20251129-2134-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -17.940 -> -17.430\n",
            "110942: done 279 games, reward -16.910, eps 0.01, speed 115.24 f/s, time 15.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-16-20251129-2136-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-16-20251129-2136-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -17.430 -> -16.910\n",
            "132666: done 309 games, reward -16.390, eps 0.01, speed 128.47 f/s, time 18.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-16-20251129-2139-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-16-20251129-2139-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -16.910 -> -16.390\n",
            "151337: done 333 games, reward -15.840, eps 0.01, speed 130.18 f/s, time 20.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-15-20251129-2141-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-15-20251129-2141-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -16.390 -> -15.840\n",
            "178816: done 369 games, reward -15.320, eps 0.01, speed 121.70 f/s, time 24.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-15-20251129-2145-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-15-20251129-2145-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -15.840 -> -15.320\n",
            "191214: done 385 games, reward -14.810, eps 0.01, speed 127.20 f/s, time 26.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-14-20251129-2147-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-14-20251129-2147-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -15.320 -> -14.810\n",
            "231690: done 438 games, reward -14.290, eps 0.01, speed 125.94 f/s, time 31.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-14-20251129-2152-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-14-20251129-2152-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -14.810 -> -14.290\n",
            "282028: done 504 games, reward -13.780, eps 0.01, speed 127.87 f/s, time 38.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-13-20251129-2159-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-13-20251129-2159-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -14.290 -> -13.780\n",
            "310333: done 539 games, reward -13.250, eps 0.01, speed 111.91 f/s, time 42.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-13-20251129-2203-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-13-20251129-2203-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -13.780 -> -13.250\n",
            "322137: done 553 games, reward -12.690, eps 0.01, speed 127.75 f/s, time 44.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-12-20251129-2205-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-12-20251129-2205-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -13.250 -> -12.690\n",
            "331696: done 564 games, reward -12.180, eps 0.01, speed 117.74 f/s, time 45.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-12-20251129-2206-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-12-20251129-2206-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -12.690 -> -12.180\n",
            "345508: done 581 games, reward -11.670, eps 0.01, speed 125.77 f/s, time 47.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-11-20251129-2208-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-11-20251129-2208-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -12.180 -> -11.670\n",
            "368034: done 609 games, reward -11.140, eps 0.01, speed 123.21 f/s, time 50.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-11-20251129-2211-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-11-20251129-2211-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -11.670 -> -11.140\n",
            "517788: done 792 games, reward -10.580, eps 0.01, speed 116.71 f/s, time 72.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-10-20251129-2232-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-10-20251129-2232-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -11.140 -> -10.580\n",
            "530393: done 806 games, reward -10.020, eps 0.01, speed 127.83 f/s, time 73.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-10-20251129-2234-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-10-20251129-2234-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -10.580 -> -10.020\n",
            "589287: done 875 games, reward -9.500, eps 0.01, speed 115.80 f/s, time 82.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-9-20251129-2243-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-9-20251129-2243-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -10.020 -> -9.500\n",
            "670044: done 965 games, reward -8.990, eps 0.01, speed 117.33 f/s, time 93.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-8-20251129-2254-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-8-20251129-2254-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -9.500 -> -8.990\n",
            "687042: done 982 games, reward -8.440, eps 0.01, speed 127.14 f/s, time 95.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-8-20251129-2256-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-8-20251129-2256-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -8.990 -> -8.440\n",
            "701719: done 999 games, reward -7.930, eps 0.01, speed 120.68 f/s, time 98.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-7-20251129-2258-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-7-20251129-2258-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -8.440 -> -7.930\n",
            "722636: done 1022 games, reward -7.380, eps 0.01, speed 119.91 f/s, time 100.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-7-20251129-2301-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-7-20251129-2301-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -7.930 -> -7.380\n",
            "1095728: done 1455 games, reward -6.840, eps 0.01, speed 121.74 f/s, time 152.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2352-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-6-20251129-2352-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -7.380 -> -6.840\n",
            "1120976: done 1482 games, reward -6.300, eps 0.01, speed 126.18 f/s, time 155.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            " - Local:        saved_models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Best reward updated -6.840 -> -6.300\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2694324418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPSILON_FINAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPSILON_START\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPSILON_DECAY_LAST_FRAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1076658906.py\u001b[0m in \u001b[0;36mplay_step\u001b[0;34m(self, net, device, epsilon)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# do step in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAtariStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    325\u001b[0m     ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n\u001b[1;32m    326\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ale_py/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_terminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_truncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "paths = sorted(glob.glob(\"/content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_*pong_ddqn_variant*.dat\"))\n",
        "for p in paths:\n",
        "    print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMXAqcerXs4w",
        "outputId": "fd6a586a-1dd2-4c9a-9c4b-0d0490936aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "eval_env = make_env(DEFAULT_ENV_NAME, render_mode=None)\n",
        "\n",
        "eval_net = DQN(eval_env.observation_space.shape, eval_env.action_space.n).to(device)\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "eval_net.load_state_dict(state_dict)\n",
        "eval_net.eval()\n",
        "\n",
        "print(\"Loaded model:\", MODEL_PATH)\n",
        "\n",
        "# Runs greedy evaluation episodes\n",
        "@torch.no_grad()\n",
        "def evaluate_agent(env, net, device, n_episodes=30):\n",
        "    rewards = []\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        state, _ = env.reset()\n",
        "        done = False\n",
        "        truncated = False\n",
        "        total_reward = 0.0\n",
        "\n",
        "        # Play one full episode\n",
        "        while not (done or truncated):\n",
        "            state_v = torch.as_tensor(state).unsqueeze(0).to(device)\n",
        "            q_vals = net(state_v)\n",
        "            action = int(q_vals.argmax(dim=1).item())\n",
        "\n",
        "            next_state, reward, done, truncated, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        print(f\"Episode {ep+1}: reward = {total_reward}\")\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    rewards = np.array(rewards, dtype=np.float32)\n",
        "\n",
        "    print(\"\\n===== DDQN Evaluation Summary =====\")\n",
        "    print(f\"Episodes: {n_episodes}\")\n",
        "    print(f\"Mean reward: {rewards.mean():.3f}\")\n",
        "    print(f\"Std reward:  {rewards.std():.3f}\")\n",
        "    print(f\"Min reward:  {rewards.min():.3f}\")\n",
        "    print(f\"Max reward:  {rewards.max():.3f}\")\n",
        "    print(\"===================================\")\n",
        "\n",
        "    return rewards, rewards.mean(), rewards.std()\n",
        "\n",
        "ddqn_rewards, ddqn_mean, ddqn_std = evaluate_agent(eval_env, eval_net, device, n_episodes=30)\n",
        "\n",
        "eval_env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7lcn3AzMAVv",
        "outputId": "d90d9187-cb21-403b-b41d-b65762b813a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Pong-v5\n",
            "Loaded model: /content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\n",
            "Episode 1: reward = 1.0\n",
            "Episode 2: reward = -6.0\n",
            "Episode 3: reward = 4.0\n",
            "Episode 4: reward = 6.0\n",
            "Episode 5: reward = -9.0\n",
            "Episode 6: reward = -7.0\n",
            "Episode 7: reward = -2.0\n",
            "Episode 8: reward = -2.0\n",
            "Episode 9: reward = -1.0\n",
            "Episode 10: reward = 1.0\n",
            "Episode 11: reward = -6.0\n",
            "Episode 12: reward = -8.0\n",
            "Episode 13: reward = -2.0\n",
            "Episode 14: reward = -9.0\n",
            "Episode 15: reward = 1.0\n",
            "Episode 16: reward = 9.0\n",
            "Episode 17: reward = -1.0\n",
            "Episode 18: reward = -6.0\n",
            "Episode 19: reward = -12.0\n",
            "Episode 20: reward = -7.0\n",
            "Episode 21: reward = -5.0\n",
            "Episode 22: reward = 5.0\n",
            "Episode 23: reward = -1.0\n",
            "Episode 24: reward = -10.0\n",
            "Episode 25: reward = -9.0\n",
            "Episode 26: reward = -1.0\n",
            "Episode 27: reward = -8.0\n",
            "Episode 28: reward = -11.0\n",
            "Episode 29: reward = -5.0\n",
            "Episode 30: reward = -4.0\n",
            "\n",
            "===== DDQN Evaluation Summary =====\n",
            "Episodes: 30\n",
            "Mean reward: -3.500\n",
            "Std reward:  5.220\n",
            "Min reward:  -12.000\n",
            "Max reward:  9.000\n",
            "===================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DDQN Evaluation on ALE/Pong-v5\n",
        "\n",
        "For this experiment I trained a Double DQN (DDQN)-style agent on ALE/Pong-v5 with:\n",
        "\n",
        "- Frame stacking of 4 frames  \n",
        "- Replay buffer size: 10,000 transitions  \n",
        "- Discount factor: Î³ = 0.99  \n",
        "- Adam optimizer with learning rate 1e-4  \n",
        "- Target network update every 500 frames  \n",
        "- Epsilon-greedy exploration:\n",
        "  - Îµ_start = 1.0 â†’ Îµ_final = 0.01\n",
        "  - Linear decay over 10,000 frames  \n",
        "\n",
        "During training I saved the best-performing checkpoint based on the moving average reward over the last 100 games. The final saved model was:\n",
        "\n",
        "`ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat`\n",
        "\n",
        "After training I froze the network weights and evaluated the agent with a greedy policy (always taking the argmax Q-value) for 30 episodes.\n",
        "\n",
        "From the printed evaluation summary, I obtained:\n",
        "\n",
        "- Number of episodes: 30  \n",
        "- Mean reward: **-3.50**  \n",
        "- Standard deviation: **5.22**  \n",
        "- Minimum reward: **-12**  \n",
        "- Maximum reward: **9**  \n",
        "\n",
        "These values are taken directly from the `DDQN Evaluation Summary` printed by the notebook.\n"
      ],
      "metadata": {
        "id": "6FlOEV16jkKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline DQN (My Own Training Run)\n",
        "\n",
        "To compare fairly against my Double DQN results, I first trained **my own DQN baseline** on **ALE/Pong-v5** using the same convolutional architecture and Atari preprocessing that I later reused for DDQN. This ensures both models share the same input representation, frame stacking, and network capacity.\n",
        "\n",
        "For this baseline run, I used a **fast training configuration**:\n",
        "\n",
        "- Replay buffer size: **10,000**\n",
        "- Replay start size: **1,000** transitions before training\n",
        "- Discount factor: **Î³ = 0.99**\n",
        "- Optimizer: **Adam**, learning rate **1e-4**\n",
        "- Target network update: every **500** frames\n",
        "- Exploration schedule:\n",
        "  - Îµ starts at **1.0**\n",
        "  - linearly decays to **0.01**\n",
        "  - over **10,000** frames\n",
        "\n",
        "During training, I tracked the moving-average reward (last 100 games).  \n",
        "The agent started at roughly **â€“21**, consistently losing, and gradually improved to about **â€“8.3** by ~**298k** frames.\n",
        "\n",
        "This run now serves as **my official DQN baseline**, replacing the instructorâ€™s reference curve.\n"
      ],
      "metadata": {
        "id": "mWPdBGPCZGY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === My DQN baseline (from my own run) ===\n",
        "my_dqn_steps = [\n",
        "    189, 2516, 23040, 33071, 39679, 43919, 50699, 56038,\n",
        "    62671, 70235, 82748, 100461, 108510, 112642, 120593,\n",
        "    127373, 132300, 137391, 142959, 150067, 163646,\n",
        "    249390, 286860, 298454\n",
        "]\n",
        "\n",
        "my_dqn_mean_rewards = [\n",
        "    -21.000, -20.455, -19.947, -19.440, -18.920, -18.410,\n",
        "    -17.860, -17.340, -16.760, -16.220, -15.630, -15.110,\n",
        "    -14.600, -14.050, -13.340, -12.720, -12.210, -11.610,\n",
        "    -11.000, -10.450, -9.900, -9.330, -8.820, -8.310\n",
        "]\n",
        "\n",
        "# === My Double DQN (variant) run ===\n",
        "ddqn_steps = [\n",
        "    230, 54212, 62345, 73047, 85516, 98988, 110942, 132666,\n",
        "    151337, 178816, 191214, 231690, 282028, 310333, 322137,\n",
        "    331696, 345508, 368034, 517788, 530393, 589287, 670044,\n",
        "    687042, 701719, 722636, 1095728, 1120976\n",
        "]\n",
        "\n",
        "ddqn_mean_rewards = [\n",
        "    -20.000, -19.490, -18.980, -18.460, -17.940, -17.430,\n",
        "    -16.910, -16.390, -15.840, -15.320, -14.810, -14.290,\n",
        "    -13.780, -13.250, -12.690, -12.180, -11.670, -11.140,\n",
        "    -10.580, -10.020, -9.500, -8.990, -8.440, -7.930,\n",
        "    -7.380, -6.840, -6.300\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dqn_steps, my_dqn_mean_rewards, marker=\"o\", label=\"My DQN baseline\")\n",
        "plt.plot(ddqn_steps, ddqn_mean_rewards, marker=\"s\", label=\"My Double DQN (variant)\")\n",
        "plt.axhline(0.0, linestyle=\"--\", linewidth=1)\n",
        "\n",
        "plt.xlabel(\"Training frames\")\n",
        "plt.ylabel(\"Mean reward (last 100 games)\")\n",
        "plt.title(\"Training Curves: My DQN baseline vs My Double DQN on ALE/Pong-v5\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "QZjk5BMu3IdZ",
        "outputId": "d8edba78-c020-4eaa-fc7a-da171db261fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import os\n",
        "\n",
        "video_dir = \"/content/drive/MyDrive/PUBLIC/Videos\"\n",
        "os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "def record_policy_video(filename, env_name, net=None, device=\"cpu\", max_frames=1500, epsilon_random=0.0):\n",
        "    env = make_env(env_name, n_steps=4, render_mode=\"rgb_array\")\n",
        "    frames = []\n",
        "\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    truncated = False\n",
        "    steps = 0\n",
        "\n",
        "    while not (done or truncated) and steps < max_frames:\n",
        "        if (net is None) or (np.random.rand() < epsilon_random):\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_v = torch.as_tensor(state).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                q_vals = net(state_v)\n",
        "            action = int(q_vals.argmax(dim=1).item())\n",
        "\n",
        "        next_state, reward, done, truncated, _ = env.step(action)\n",
        "        frames.append(env.render())\n",
        "        state = next_state\n",
        "        steps += 1\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    out_path = os.path.join(video_dir, filename)\n",
        "    imageio.mimsave(out_path, frames, fps=30)\n",
        "    print(\"Saved video to:\", out_path)"
      ],
      "metadata": {
        "id": "sXKxtNMOUAPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random / early video\n",
        "record_policy_video(\n",
        "    filename=\"pong_early_random.mp4\",\n",
        "    env_name=DEFAULT_ENV_NAME,\n",
        "    net=None,\n",
        "    device=device,\n",
        "    epsilon_random=1.0,\n",
        ")\n",
        "\n",
        "# load DDQN model\n",
        "ddqn_model_path = \"/content/drive/MyDrive/PUBLIC/Models/ALE_Pong-v5-best_-6-20251129-2356-pong_ddqn_variant_epsdec10000_rs1000_sync500.dat\"\n",
        "\n",
        "tmp_env = make_env(DEFAULT_ENV_NAME, render_mode=None)\n",
        "play_net = DQN(tmp_env.observation_space.shape, tmp_env.action_space.n).to(device)\n",
        "play_net.load_state_dict(torch.load(ddqn_model_path, map_location=device))\n",
        "play_net.eval()\n",
        "tmp_env.close()\n",
        "\n",
        "# learned DDQN video\n",
        "record_policy_video(\n",
        "    filename=\"pong_ddqn_learned.mp4\",\n",
        "    env_name=DEFAULT_ENV_NAME,\n",
        "    net=play_net,\n",
        "    device=device,\n",
        "    epsilon_random=0.0,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0my5MD5vUCWu",
        "outputId": "635e0a6a-fb47-4937-b667-3821220a6389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/Pong-v5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video to: /content/drive/MyDrive/PUBLIC/Videos/pong_early_random.mp4\n",
            "Creating environment ALE/Pong-v5\n",
            "Creating environment ALE/Pong-v5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video to: /content/drive/MyDrive/PUBLIC/Videos/pong_ddqn_learned.mp4\n"
          ]
        }
      ]
    }
  ]
}